{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdaec706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:50:20.549812Z",
     "iopub.status.busy": "2023-11-05T00:50:20.549304Z",
     "iopub.status.idle": "2023-11-05T00:50:28.426659Z",
     "shell.execute_reply": "2023-11-05T00:50:28.425617Z"
    },
    "papermill": {
     "duration": 7.883313,
     "end_time": "2023-11-05T00:50:28.428826",
     "exception": false,
     "start_time": "2023-11-05T00:50:20.545513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e69e340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:50:28.437762Z",
     "iopub.status.busy": "2023-11-05T00:50:28.436699Z",
     "iopub.status.idle": "2023-11-05T00:50:32.852298Z",
     "shell.execute_reply": "2023-11-05T00:50:32.851189Z"
    },
    "papermill": {
     "duration": 4.422026,
     "end_time": "2023-11-05T00:50:32.854410",
     "exception": false,
     "start_time": "2023-11-05T00:50:28.432384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1856 files belonging to 2 classes.\n",
      "Using 1485 files for training.\n",
      "Found 1856 files belonging to 2 classes.\n",
      "Using 371 files for validation.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR =\"/kaggle/input/tyre-quality-classification/Digital images of defective and good condition tyres\"\n",
    "\n",
    "train_dataset = image_dataset_from_directory(TRAINING_DIR, validation_split=0.2,label_mode='categorical', subset=\"training\", seed=42, image_size=(256, 256),\n",
    "                                  \n",
    "                                             batch_size=16)\n",
    "\n",
    "val_dataset = image_dataset_from_directory(TRAINING_DIR, validation_split=0.2,label_mode='categorical', subset=\"validation\", seed=42, image_size=(256, 256),\n",
    "                                           batch_size=16)\n",
    "\n",
    "# train_dataset = train_dataset.map(lambda x, y: (datagen.flow(x, batch_size=64), y))\n",
    "# train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6c1da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T00:50:32.863260Z",
     "iopub.status.busy": "2023-11-05T00:50:32.862983Z",
     "iopub.status.idle": "2023-11-05T00:50:32.873983Z",
     "shell.execute_reply": "2023-11-05T00:50:32.872743Z"
    },
    "papermill": {
     "duration": 0.01711,
     "end_time": "2023-11-05T00:50:32.875368",
     "exception": true,
     "start_time": "2023-11-05T00:50:32.858258",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3491532401.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    tf.keras.layers.GlobalAveragePooling2D()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#################TRY DIFFERENT TRANSFER LEARNING MODELS########################\n",
    "model_name='resnet101'\n",
    "TL_layer = tf.keras.applications.resnet.ResNet101(input_shape=(256, 256, 3), \n",
    "                                                              include_top=False, weights='imagenet')\n",
    "TL_layer.trainable = False\n",
    "#################################################################################\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(256, 256, 3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomHeight(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomWidth(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.Resizing(256,256),\n",
    "    TL_layer,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "old =0\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self,epoch,logs={}):\n",
    "            global old\n",
    "            if(logs.get('val_acc') > old):\n",
    "                #change model name here\n",
    "                model.save(model_name+'.h5',overwrite=True)\n",
    "                old = logs.get('val_acc')\n",
    "                print(\"\\n new best found threshold now = \",old)\n",
    "                \n",
    "saver =myCallback()\n",
    "history = model.fit_generator(train_dataset,\n",
    "                              epochs=200,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_dataset,callbacks=[saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff3ce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T18:34:41.042934Z",
     "iopub.status.busy": "2023-10-09T18:34:41.042517Z",
     "iopub.status.idle": "2023-10-09T18:35:20.684308Z",
     "shell.execute_reply": "2023-10-09T18:35:20.682757Z",
     "shell.execute_reply.started": "2023-10-09T18:34:41.042899Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ace010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T18:48:08.643857Z",
     "iopub.status.busy": "2023-10-09T18:48:08.643527Z",
     "iopub.status.idle": "2023-10-09T23:16:53.164514Z",
     "shell.execute_reply": "2023-10-09T23:16:53.163271Z",
     "shell.execute_reply.started": "2023-10-09T18:48:08.643830Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CUSTOM MODEL IMPLEMENTATION\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(256, 256, 3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomHeight(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomWidth(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.Resizing(256,256),\n",
    "    tf.keras.layers.Conv2D(1024, (5, 5), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Conv2D(512, (3, 3), padding = 'same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3),  activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3),   activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3),  activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "old =0\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self,epoch,logs={}):\n",
    "            global old\n",
    "            if(logs.get('val_acc') > old):\n",
    "                #change model name here\n",
    "                model.save('model_tire_RESNET101.h5',overwrite=True)\n",
    "                old = logs.get('val_acc')\n",
    "                print(\"\\n new best found threshold now = \",old)\n",
    "                \n",
    "saver =myCallback()\n",
    "history = model.fit_generator(train_dataset,\n",
    "                              epochs=200,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_dataset,callbacks=[saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee2c2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T23:16:53.167402Z",
     "iopub.status.busy": "2023-10-09T23:16:53.166706Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_dataset,\n",
    "                              epochs=200,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_dataset,callbacks=[saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46c14f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# read the image\n",
    "# img = cv2.imread('./data/tire-dataset/flat.class/00150.jpg')\n",
    "img = cv2.imread('./data/source/defective/Defective (7).jpg')\n",
    "class_index = 1\n",
    "num_classes = 2\n",
    "\n",
    "# format it to be in the RGB colorspace\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "# resize to 300x300 and normalize pixel values to be in the range [0, 1]\n",
    "img = cv2.resize(img, (256, 256)) / 255.0\n",
    "\n",
    "# add a batch dimension in front\n",
    "image = np.expand_dims(img, axis=0)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# Siberian Husky's class ID in ImageNet\n",
    "\n",
    "\n",
    "\n",
    "# convert to one hot representation to match our softmax activation in the model definition\n",
    "expected_output = tf.one_hot([class_index] * image.shape[0], num_classes)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # cast image to float\n",
    "    inputs = tf.cast(image, tf.float32)\n",
    "\n",
    "    # watch the input pixels\n",
    "    tape.watch(inputs)\n",
    "\n",
    "    # generate the predictions\n",
    "    predictions = model(inputs)\n",
    "\n",
    "    # get the loss\n",
    "    loss = tf.keras.losses.categorical_crossentropy(\n",
    "        expected_output, predictions\n",
    "    )\n",
    "\n",
    "# get the gradient with respect to the inputs\n",
    "gradients = tape.gradient(loss, inputs)\n",
    "grayscale_tensor = tf.reduce_sum(tf.abs(gradients), axis=-1)\n",
    "\n",
    "normalized_tensor = tf.cast(\n",
    "    255\n",
    "    * (grayscale_tensor - tf.reduce_min(grayscale_tensor))\n",
    "    / (tf.reduce_max(grayscale_tensor) - tf.reduce_min(grayscale_tensor)),\n",
    "    tf.uint8,\n",
    ")\n",
    "\n",
    "# remove the channel dimension to make the tensor a 2d tensor\n",
    "normalized_tensor = tf.squeeze(normalized_tensor)\n",
    "\n",
    "gradient_color = cv2.applyColorMap(normalized_tensor.numpy(), cv2.COLORMAP_HOT)\n",
    "\n",
    "gradient_color = gradient_color / 255.0\n",
    "super_imposed = cv2.addWeighted(img, 0.8, gradient_color, 0.8, 0.0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(super_imposed)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(normalized_tensor)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# print(expected_output,np.argmax(tf.keras.activations.softmax(predictions)))\n",
    "\n",
    "# # Set a threshold for high activations\n",
    "# threshold = 0.5  # Adjust this threshold as needed\n",
    "\n",
    "# # Filter out pixels below the threshold\n",
    "# high_activation_pixels = normalized_tensor.numpy() > threshold\n",
    "\n",
    "# # Create a mask for high activations\n",
    "# high_activation_mask = np.zeros_like(img)\n",
    "# high_activation_mask[high_activation_pixels] = img[high_activation_pixels]\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.imshow(high_activation_mask)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.51868,
   "end_time": "2023-11-05T00:50:36.026832",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-05T00:50:16.508152",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
